"""
Test Real LLM Integration with OpenAI API
"""

import os
from config import TechnicalAgentConfig, get_config
from llm_integration import LLMSpecificationParser

def test_real_llm():
    """Test LLM features with real OpenAI API"""
    
    print("\n" + "="*70)
    print("TESTING REAL LLM INTEGRATION")
    print("="*70)
    
    # Check for API key
    api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        print("\n‚ùå OPENAI_API_KEY not found in environment variables")
        print("\nTo set it, run:")
        print('  $env:OPENAI_API_KEY = "sk-your-key-here"')
        print("\nOr permanently:")
        print('  [System.Environment]::SetEnvironmentVariable("OPENAI_API_KEY", "sk-your-key", "User")')
        return False
    
    print(f"\n‚úÖ OpenAI API Key found: {api_key[:20]}...")
    
    # Initialize configuration
    config = get_config()
    
    # Disable mock mode to use real API
    config.disable_mock_mode()
    config.set('llm', 'provider', value='openai')
    config.set('llm', 'openai_model', value='gpt-4o-mini')  # Using gpt-4o-mini (faster and cheaper)
    
    print("\nüìã Configuration:")
    print(f"  Provider: {config.get('llm', 'provider')}")
    print(f"  Model: {config.get('llm', 'openai_model')}")
    print(f"  Mock Mode: {config.get('llm', 'use_mock')}")
    
    # Initialize LLM parser
    print("\nü§ñ Initializing LLM Parser...")
    try:
        llm = LLMSpecificationParser(
            provider='openai', 
            api_key=api_key,
            model='gpt-4o-mini'  # Use gpt-4o-mini which is available
        )
        print("‚úÖ LLM Parser initialized successfully")
    except Exception as e:
        print(f"‚ùå Failed to initialize LLM Parser: {e}")
        return False
    
    # Test 1: Parse Technical Specification
    print("\n" + "="*70)
    print("TEST 1: LLM SPECIFICATION PARSING")
    print("="*70)
    
    rfp_text = """
    Supply and installation of 100A, 415V, 3-phase XLPE insulated aluminum conductor 
    cables as per IS 694:2010 standard. The cables must be BIS certified (ISI mark) 
    and suitable for outdoor installation with UV resistance. Total quantity: 500 meters.
    Delivery required within 30 days.
    """
    
    print(f"\nüìÑ RFP Text:\n{rfp_text.strip()}")
    
    print("\n‚è≥ Calling OpenAI GPT-4 API...")
    try:
        result = llm.parse_technical_specification(rfp_text)
        
        print("\n‚úÖ API Response Received!")
        print("\nüìä Extracted Specifications:")
        for key, value in result.get('specifications', {}).items():
            print(f"   ‚Ä¢ {key}: {value}")
        
        print("\nüìú Identified Standards:")
        for std in result.get('standards', []):
            print(f"   ‚Ä¢ {std}")
        
        print("\nüèÖ Required Certifications:")
        for cert in result.get('certifications', []):
            print(f"   ‚Ä¢ {cert}")
        
        print(f"\nüéØ Confidence: {result.get('confidence', 0)*100:.0f}%")
        
    except Exception as e:
        print(f"‚ùå API call failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test 2: Specification Explanation
    print("\n" + "="*70)
    print("TEST 2: SPECIFICATION EXPLANATION")
    print("="*70)
    
    print("\n‚è≥ Generating explanation for 'voltage: 415V'...")
    try:
        explanation = llm.explain_specification("voltage", "415V")
        print(f"\n‚úÖ Explanation:\n{explanation}")
    except Exception as e:
        print(f"‚ùå Explanation failed: {e}")
    
    # Test 3: Technical Risk Assessment
    print("\n" + "="*70)
    print("TEST 3: TECHNICAL RISK ASSESSMENT")
    print("="*70)
    
    print("\n‚è≥ Assessing technical risk...")
    try:
        risk = llm.assess_technical_risk(
            requirement={"voltage": "415V", "current": "100A", "standard": "IS 694"},
            match={"voltage": "415V", "current": "100A", "standard": "IS 694", "certification": "BIS"}
        )
        
        print(f"\n‚úÖ Risk Assessment:")
        print(f"   Risk Level: {risk.get('risk_level', 'N/A')}")
        print(f"   Risk Score: {risk.get('risk_score', 0)*100:.0f}%")
        
        if risk.get('risks'):
            print(f"\n   Risk Factors:")
            for r in risk['risks'][:3]:
                print(f"   ‚Ä¢ {r}")
        
        if risk.get('mitigations'):
            print(f"\n   Mitigations:")
            for m in risk['mitigations'][:3]:
                print(f"   ‚Ä¢ {m}")
                
    except Exception as e:
        print(f"‚ùå Risk assessment failed: {e}")
    
    # Success
    print("\n" + "="*70)
    print("‚úÖ ALL REAL LLM TESTS PASSED!")
    print("="*70)
    
    print("\nüìä Summary:")
    print("   ‚úÖ OpenAI API connection working")
    print("   ‚úÖ GPT-4 model responding")
    print("   ‚úÖ Specification parsing working")
    print("   ‚úÖ Explanation generation working")
    print("   ‚úÖ Risk assessment working")
    
    print("\nüí° Your OpenAI API key is configured correctly!")
    print("   All LLM features are now available for production use.")
    
    return True


if __name__ == "__main__":
    success = test_real_llm()
    
    if success:
        print("\nüéâ You can now use LLM features in the Technical Agent!")
        print("\nNext steps:")
        print("   1. Run: python demo_optional_features.py")
        print("   2. The agent will use real GPT-4 instead of mock responses")
        print("   3. Enjoy AI-powered specification analysis!")
    else:
        print("\n‚ö†Ô∏è Please set your OpenAI API key and try again.")
